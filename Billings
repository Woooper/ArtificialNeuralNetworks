from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import numpy as np

hatalar = np.array([0]).reshape(1,1)

for dongu in range (20):   # 20 sonuç değerleri alınacak.
    
    # y(k) fonksiyonunun ilk 3 değerini 0 alarak başlanır.
    
    y = np.array([0,0,0]).reshape(3,1)
    
    # Ödev dosyasındaki y(k) fonksiyonu yazılır.
    
    def billings (y,k):
        return (0.8-5*np.exp(-((y[k-1])**2))*y[k-1]-(0.3+0.9*np.exp(-((y[k-1])**2)))*y[k-2]+0.1*np.sin(np.pi*y[k-1])+np.random.rand(1,1)*0.01)
    
    # Toplam 50 adet çıkış değeri olması için döngü oluşturulur.
    for i in range (106):
        y = np.concatenate((y,billings(y,i+3)))
    
    # ilk 3 sıfır değeri atılır.
    y = y[3:]
    
    # Giriş ve çıkışlar belirlenir.
    
    girisler = np.array([0,0,0]).reshape(1,3)
    cikislar = np.array([0]).reshape(1,1)
    for i in range (100):
            girisler = np.concatenate((girisler,y[i:i+3].reshape(1,3)))
            cikislar = np.concatenate((cikislar,y[i+3].reshape(1,1)))
    girisler = girisler[1:]
    cikislar = cikislar[1:]
    
    # Giriş ve çıkışlar normalize edilir.
    
    a = girisler.max()-girisler.min()
    girisler = (2*girisler/a)
    cikislar = (2*cikislar/a)
    
    # Eğitim ve test grupları ayrılır.
    
    x_train,x_test,y_train,y_test = train_test_split(girisler,cikislar,test_size=0.24,random_state=dongu*2)
    
    # Çıkış Değerlerimiz yaklaşık -1 ile 1 arasında olduğu için aktivasyon fonksiyonu tanjant hiperbolik olabilir. Reel sayılarla çalıştığımız için x/4 kullanılmıştır.
    
    def akt(x):
        return ((-1*girisler.min())*(np.exp(x/4)-np.exp(-x/4))/(np.exp(-x/4)+np.exp(x/4)))
    def akt_turev(x):
        return (-1*girisler.min()*(np.exp(x/2))/((np.exp(x/2)+1)**2))

    # Model Kurma
    # Çıkış Değerlerimiz -2.5 ile 2.5 arasında olduğu için aktivasyon fonksiyonu tanjant hiperbolik olabilir.
    hiz = np.array([0.5,0.7,0.8,0.7])
    momentum = np.array([0.4,0.6,0.7,0.6])
    x_train_b = np.hstack ((x_train, [[1]] * len (x_train)))
    W1 = 0.2 * np.random.rand(6,len(x_train_b.T))
    W2 = 5 * np.random.rand(4,len(W1)+1)
    W3 = 3 * np.random.rand(8,len(W2)+1)
    W4 = 4*np.random.rand(1,len(W3)+1)
    hata_liste = np.array([])
    ton=0
    ht=1
    dongu=0
    cikis_list = np.zeros((len(x_train),1))
    while ht >= 0.02:
        ton=0
        dongu=dongu+1
        moment_1=W1
        moment_2=W2
        moment_3=W3
        moment_4=W4
        for ii in (x_train_b):    
            nod = np.matmul(W1,ii.reshape(len(ii.T),1))
            nod_list = nod
            mid = akt(nod)        
            mid = np.concatenate((mid,np.array([1]).reshape(1,1)))
            nod2 = np.matmul(W2,mid)
            nod2_list = nod2
            mid2 = akt(nod2)
            mid2 = np.concatenate((mid2,np.array([1]).reshape(1,1)))
            nod3 = np.matmul(W3,mid2)
            nod3_list = nod3
            mid3 = akt(nod3)
            mid3 = np.concatenate((mid3,np.array([1]).reshape(1,1)))
            son = np.matmul(W4,mid3)
            cikis = akt(son)
            hata = y_train[ton].reshape(len(W4),1)-cikis
            grad_cikis = hata*akt_turev(son)
            grad_3 = np.matmul(W4.T[:-1],grad_cikis)*akt_turev(nod3_list)
            grad_2 = np.matmul(W3.T[:-1],grad_3)*akt_turev(nod2_list)
            grad_1 = np.matmul(W2.T[:-1],grad_2)*akt_turev(nod_list)
            a4=W4
            a3=W3
            a2=W2
            a1=W1
            W4 = W4+hiz[3]*np.matmul(grad_cikis,mid3.reshape(1,len(mid3)))+momentum[3]*(W4-moment_4)
            W3 = W3+(hiz[2]*np.matmul(grad_3,mid2.reshape(1,len(mid2))))+momentum[2]*(W3-moment_3)
            W2 = W2+hiz[1]*np.matmul(grad_2,mid.reshape(1,len(mid)))+momentum[1]*(W2-moment_2)
            W1 = W1+hiz[0]*np.matmul(grad_1,ii.reshape(1,len(ii)))+momentum[0]*(W1-moment_1)
            moment_4=a4
            moment_3=a3
            moment_2=a2
            moment_1=a1
            cikis_list[ton]=cikis.reshape(1,1)
            mid = np.zeros((3))
            mid2 = np.zeros((3))
            mid3 = np.zeros((3))
            ton+=1
        ht = np.array([np.sqrt(mean_squared_error(cikis_list,y_train))])
        hata_liste = np.concatenate((hata_liste, ht))
    
    # Eğitim sonuçlarını çizdirmek için alttaki bölüm yorumdan çıkarılabilir. 
    #plt.scatter(np.arange(len(y_train)),cikis_list,c='b',label='Eğitim Çıktıları')
    #plt.scatter(np.arange(len(y_train)),y_train,c='r',label='Gerçek Eğitim Değerleri')
    
    # Hata değişimi çizdirilir.
    plt.figure()
    plt.scatter(np.arange(len(hata_liste)-1),hata_liste[1:])
    
    # Test Bölgesi
    cikis_liste = np.ones(1)
    x_test_b = np.hstack ((x_test, [[1]] * len (x_test)))
    for ii in (x_test_b):    
        nod = np.matmul(W1,ii.reshape(len(ii.T),1))
        nod_list = nod
        mid = akt(nod)        
        mid = np.concatenate((mid,np.array([1]).reshape(1,1)))
        nod2 = np.matmul(W2,mid)
        nod2_list = nod2
        mid2 = akt(nod2)
        mid2 = np.concatenate((mid2,np.array([1]).reshape(1,1)))
        nod3 = np.matmul(W3,mid2)
        nod3_list = nod3
        mid3 = akt(nod3)
        mid3 = np.concatenate((mid3,np.array([1]).reshape(1,1)))
        son = np.matmul(W4,mid3)
        cikis = akt(son)
        cikis_liste = np.concatenate((cikis_liste,cikis.reshape(1)))
    
    #Test sonuçları çizdirilir.
    plt.figure()
    plt.plot(np.arange(len(y_test)),cikis_liste[1:],'g-')
    plt.plot(np.arange(len(y_test)),y_test,'y--')
    plt.scatter(np.arange(len(y_test)),cikis_liste[1:],c='b',label='Test Çıktıları')
    plt.scatter(np.arange(len(y_test)),y_test,c='r',label='Gerçek Test Değerleri')
    plt.legend()
    hatalar = np.concatenate((hatalar,np.sqrt(mean_squared_error(cikis_liste[1:],y_test)).reshape(1,1)))
    print('Ortalama Test Hatası : ' , np.sqrt(mean_squared_error(cikis_liste[1:],y_test)))
print('\n', hatalar[1:],'\n')
print('\n', hatalar[1:].mean(),'\n')
print('\n',hatalar[1:].std())
